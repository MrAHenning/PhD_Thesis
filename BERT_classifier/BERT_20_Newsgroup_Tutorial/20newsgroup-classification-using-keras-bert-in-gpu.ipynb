{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Keras-BERT and adapters available in keras for finetuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-bert\r\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/73/b970d92605129084de79accb104f3693dff9379c8300abea4369d70db8a8/keras-bert-0.78.0.tar.gz\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from keras-bert) (1.17.0)\r\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras-bert) (2.2.4)\r\n",
      "Collecting keras-transformer>=0.30.0 (from keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/83/4c/972325395b38547df8a74be89e980922c1dc9f921cc2eb613e086c6bc632/keras-transformer-0.30.0.tar.gz\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras->keras-bert) (5.1.2)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-bert) (1.0.8)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-bert) (1.1.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras->keras-bert) (2.9.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-bert) (1.12.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-bert) (1.2.1)\r\n",
      "Collecting keras-pos-embd>=0.10.0 (from keras-transformer>=0.30.0->keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\r\n",
      "Collecting keras-multi-head>=0.22.0 (from keras-transformer>=0.30.0->keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\r\n",
      "Collecting keras-layer-normalization>=0.12.0 (from keras-transformer>=0.30.0->keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/f3/a92ce51219280eea003911722046db17eaebf5f26679a73887a5c357abe4/keras-layer-normalization-0.13.0.tar.gz\r\n",
      "Collecting keras-position-wise-feed-forward>=0.5.0 (from keras-transformer>=0.30.0->keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\r\n",
      "Collecting keras-embed-sim>=0.7.0 (from keras-transformer>=0.30.0->keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\r\n",
      "Collecting keras-self-attention==0.41.0 (from keras-multi-head>=0.22.0->keras-transformer>=0.30.0->keras-bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\r\n",
      "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\r\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-bert: filename=keras_bert-0.78.0-cp36-none-any.whl size=37882 sha256=3810773968a5f6fbae7e088df2b4a125dd0eb8b2e918ff6310dd314eb397e400\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/9f/2a/a3/a4741e16520a3d651bf895e5fba34d886a993efdbb303ffc11\r\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.30.0-cp36-none-any.whl size=13388 sha256=367cd207d9e113db626697aaee465921fc5449c9e2e6e963ac3ab38ae9a09429\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/b5/06/e3/172763eea3a0b3046c91a75ec778c54e55f96ee0efdb79c044\r\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=4b6985878f2806bdd8fca265df124d1b7a9104b3ff2ce21508cfa142de89b4f5\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\r\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=66d30aa913621cb50df49b5d709e8c7e8f1f6e45191db7f0d91ad09ab7e08ab8\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\r\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.13.0-cp36-none-any.whl size=5209 sha256=53115f5019a645e73d0946a521da803af2a74c1f7d21e47fc037fe7433e6a05a\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/50/2b/71/d1d06f71d78c46a9912dc89a5bb46f357cf64fa05883fadc64\r\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=88be02466664fbea76b44073741f8cdfa0574d3ff49bb0c47e1aa05cb13fac2e\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\r\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4677 sha256=336729cf3fa971ef457794fbf8173b240101e86f73317358b0d7705ad3e6375f\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\r\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17289 sha256=08b6c813584fed94454257f5520fd664fd395d2d1349ef5f0c337d19db2c84fd\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\r\n",
      "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\r\n",
      "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\r\n",
      "Successfully installed keras-bert-0.78.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.13.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.30.0\r\n",
      "Collecting keras-rectified-adam\r\n",
      "  Downloading https://files.pythonhosted.org/packages/36/ee/7300b3b51037d63cb8e1890501a27584f932abaa2d5a625836ec26e3f86d/keras-rectified-adam-0.14.0.tar.gz\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from keras-rectified-adam) (1.17.0)\r\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras-rectified-adam) (2.2.4)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.0.8)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.12.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (2.9.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.2.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (1.1.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras->keras-rectified-adam) (5.1.2)\r\n",
      "Building wheels for collected packages: keras-rectified-adam\r\n",
      "  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.14.0-cp36-none-any.whl size=14744 sha256=d7f73bacace0708eca19cbe440f3d67019c9007a6fa24f2b22c7402547cb1c74\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/e5/a0/7e/00e10c4ffdfd33f050c912d0f063a89fbb4ddd3788a56027fa\r\n",
      "Successfully built keras-rectified-adam\r\n",
      "Installing collected packages: keras-rectified-adam\r\n",
      "Successfully installed keras-rectified-adam-0.14.0\r\n",
      "Archive:  uncased_L-12_H-768_A-12.zip\r\n",
      "   creating: uncased_L-12_H-768_A-12/\r\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \r\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \r\n",
      "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \r\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \r\n",
      "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-bert\n",
    "!pip install keras-rectified-adam\n",
    "\n",
    "!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip -o uncased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from chardet import detect\n",
    "import keras\n",
    "from keras_radam import RAdam\n",
    "from keras import backend as K\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "# from google.colab import drive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 7\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path to the pre trained model of BERT.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Pretrained BERT model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_trained_model_from_checkpoint(\n",
    "      config_path,\n",
    "      checkpoint_path,\n",
    "      training=True,\n",
    "      trainable=True,\n",
    "      seq_len=SEQ_LEN,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 23440896    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 128, 30522)   30522       MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 128, 30522)   0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,811,516\n",
      "Trainable params: 109,811,516\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting token dictionary from vocab of pretrained model to refer for input we will be using.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from keras_bert import Tokenizer\n",
    "token_dict = {}\n",
    "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "        \n",
    "# print(token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\n",
      "14671872/14666916 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# @title Download I20Newsgroup dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"20news-18828.tar.gz\", \n",
    "    origin=\"http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\", \n",
    "    extract=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Tokenizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(token_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making Label , index pair.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \".\".join(dataset.split(\".\")[:-2])\n",
    "txtfiles = os.listdir(datapath)\n",
    "labels = [(x, i) for i,x in enumerate(txtfiles)]\n",
    "def get_label(index):\n",
    "    for each in labels:\n",
    "        if index == each[1]:\n",
    "            return each[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data into train, test preceded by tokenizing sentences and returning test train data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [00:05<00:00, 170.06it/s]\n",
      "100%|██████████| 990/990 [00:03<00:00, 298.31it/s]\n",
      "100%|██████████| 628/628 [00:03<00:00, 178.93it/s]\n",
      "100%|██████████| 987/987 [00:04<00:00, 215.61it/s]\n",
      "100%|██████████| 775/775 [00:05<00:00, 147.29it/s]\n",
      "100%|██████████| 981/981 [00:03<00:00, 302.93it/s]\n",
      "100%|██████████| 972/972 [00:02<00:00, 405.35it/s]\n",
      "100%|██████████| 980/980 [00:04<00:00, 206.24it/s]\n",
      "100%|██████████| 994/994 [00:03<00:00, 280.48it/s]\n",
      "100%|██████████| 940/940 [00:07<00:00, 128.44it/s]\n",
      "100%|██████████| 961/961 [00:02<00:00, 357.40it/s]\n",
      "100%|██████████| 999/999 [00:04<00:00, 230.14it/s]\n",
      "100%|██████████| 991/991 [00:05<00:00, 167.65it/s]\n",
      "100%|██████████| 994/994 [00:03<00:00, 313.59it/s]\n",
      "100%|██████████| 799/799 [00:04<00:00, 190.06it/s]\n",
      "100%|██████████| 973/973 [00:04<00:00, 233.88it/s]\n",
      "100%|██████████| 982/982 [00:03<00:00, 324.08it/s]\n",
      "100%|██████████| 910/910 [00:04<00:00, 188.59it/s]\n",
      "100%|██████████| 997/997 [00:05<00:00, 171.17it/s]\n",
      "100%|██████████| 990/990 [00:04<00:00, 209.32it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_data(path, labels):\n",
    "    global tokenizer\n",
    "    indices, sentiments = [], []\n",
    "    for folder, sentiment in labels:\n",
    "        folder = os.path.join(path, folder)\n",
    "        for name in tqdm(os.listdir(folder)):\n",
    "            with open(os.path.join(folder, name), 'r', encoding=\"utf-8\", errors='ignore') as reader:\n",
    "                  text = reader.read()\n",
    "            ids, segments = tokenizer.encode(text, max_len=SEQ_LEN)\n",
    "            indices.append(ids)\n",
    "            sentiments.append(sentiment)\n",
    "    items = list(zip(indices, sentiments))\n",
    "    \n",
    "    np.random.shuffle(items)\n",
    "    test_items = items[int(0.8*len(items)):]\n",
    "    train_items = items[:int(0.8*len(items))]\n",
    "    indices_test, sentiments_test = zip(*test_items)\n",
    "    indices_train, sentiments_train = zip(*train_items)\n",
    "    indices_train = np.array(indices_train)\n",
    "    indices_test = np.array(indices_test)\n",
    "    mod_train = indices_train.shape[0] % BATCH_SIZE\n",
    "    mod_test = indices_test.shape[0] % BATCH_SIZE\n",
    "    if mod_train > 0:\n",
    "        indices_train, sentiments_train = indices_train[:-mod_train], sentiments_train[:-mod_train]\n",
    "    if mod_test > 0:\n",
    "      indices_test, sentiments_test = indices_test[:-mod_test], sentiments_test[:-mod_test]\n",
    "\n",
    "    return [indices_train, np.zeros_like(indices_train)], np.array(sentiments_train),[indices_test, np.zeros_like(indices_test)], np.array(sentiments_test)\n",
    "  \n",
    "train_path = os.path.join(os.path.dirname(dataset), '20news-18828')\n",
    "train_x, train_y, test_x, test_y = load_data(train_path, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f371fd78c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(train_y).value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f371d480a58>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_y).value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracting layer from pretrained bert model and adding a layer with softmax function to classify 20 classes of news.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model.inputs[:2]\n",
    "dense = model.get_layer('NSP-Dense').output\n",
    "outputs = keras.layers.Dense(units=20, activation='softmax')(dense)\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "  RAdam(learning_rate =LR),\n",
    "  loss='sparse_categorical_crossentropy',\n",
    "  metrics=['sparse_categorical_accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
    "init_op = tf.variables_initializer(\n",
    "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
    ")\n",
    "sess.run(init_op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, training the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "15050/15050 [==============================] - 236s 16ms/step - loss: 1.4068 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 2/7\n",
      "15050/15050 [==============================] - 214s 14ms/step - loss: 0.3577 - sparse_categorical_accuracy: 0.8896\n",
      "Epoch 3/7\n",
      "15050/15050 [==============================] - 214s 14ms/step - loss: 0.1697 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 4/7\n",
      "15050/15050 [==============================] - 214s 14ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9686\n",
      "Epoch 5/7\n",
      "15050/15050 [==============================] - 214s 14ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9737\n",
      "Epoch 6/7\n",
      "15050/15050 [==============================] - 214s 14ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 7/7\n",
      "15050/15050 [==============================] - 214s 14ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f371df4ec88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Fit\n",
    "\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making prediction for test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 19s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicts = model.predict(test_x, verbose=True).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9077333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.sum(test_y == predicts) / test_y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_text = \"\"\"The Mumbai batsman is set to replace underperforming KL Rahul as an opener in upcoming Test series against South Africa in home conditions.India’s newly-appointed batting coach Vikram Rathour feels opener Rohit Sharma is “too good a player” to not be playing in all three formats. Rathour, like many former cricketers, backed Rohit to open for India in Test cricket.“He is too good a player to not be playing in any game. That is what is everyone is thinking. He has done so well in white-ball cricket as an opener so there is no reason why he can’t succeed as a Test opener provided he gets enough opportunities,” Rathour believes Rohit can be an asset to his team if he does good against South Africa in Tests.\"\"\"\n",
    "test = \"\"\"Senate Democrats are planning to hold the floor on Tuesday evening for an hours-long talk-a-thon on the issue of gun violence.The floor marathon comes as the White House is struggling to find a place to land in the weeks-long debate over potential gun-law reforms.“Many of my colleagues have seen their communities torn apart by gun violence; some by horrific mass shootings, others by a relentless, daily stream. Many of them have worked for years to bring commonsense gun safety measures before the Senate,” Senate Minority Leader Charles Schumer (D-N.Y.) said Tuesday, in announcing the plan from the Senate floor.\"\"\"\n",
    "ids, segments = tokenizer.encode(test, max_len=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'talk.politics.guns'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpu = np.array(ids).reshape([1, SEQ_LEN])\n",
    "get_label(model.predict([inpu,np.zeros_like(inpu)]).argmax(axis=-1)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rec.sport.baseball'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids, segments = tokenizer.encode(test_text, max_len=SEQ_LEN)\n",
    "inpu = np.array(ids).reshape([1, SEQ_LEN])\n",
    "get_label(model.predict([inpu,np.zeros_like(inpu)]).argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
