{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a709836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn as sk\n",
    "import string\n",
    "from time import perf_counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
    "\n",
    "\n",
    "def pre_process(s):\n",
    "    # remove punctuation\n",
    "    s = \"\".join([char for char in s if char not in string.punctuation])\n",
    "\n",
    "    # filter stopwords\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    s_tokenized = nltk.word_tokenize(s)\n",
    "    s_tokenized_stopwords_removed = [word for word in s_tokenized if word not in stopwords]\n",
    "    s_tokenized_stopwords_removed_joined = \" \".join(s_tokenized_stopwords_removed)\n",
    "    return s_tokenized_stopwords_removed_joined\n",
    "\n",
    "\n",
    "def tokenize_tag_combine(s):\n",
    "    s_tokenized = nltk.word_tokenize(s)\n",
    "    s_pos_tagged = nltk.pos_tag(s_tokenized)\n",
    "\n",
    "    new_s = ''\n",
    "    for word, pos in s_pos_tagged:\n",
    "        new_s = new_s + word + \"_\" + pos + \" \"\n",
    "\n",
    "    return new_s\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    # read in data\n",
    "    df = pd.read_csv(r\"../classifier/data/combined.csv\")\n",
    "    df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    # get part of speech\n",
    "    test_string = \"This is a test string.\"\n",
    "    test_string = pre_process(test_string)\n",
    "    test_string = tokenize_tag_combine(test_string)\n",
    "\n",
    "    df['pos_tagged'] = df['text'].apply(tokenize_tag_combine)\n",
    "    \n",
    "    #r\"../classifier/data/combined_pos_tagged.csv\"\n",
    "    df.to_csv(r\"../classifier/data/combined_pos_tagged.csv\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label', 'pos_tagged'], dtype='object')\n",
      "                                                text        label  \\\n",
      "0  exposure to violent video games causes at leas... 0.0000000000   \n",
      "1  video game violence is not related to serious ... 0.0000000000   \n",
      "2  some violent video games may actually have a p... 0.0000000000   \n",
      "3  exposure to violent video games causes both sh... 0.0000000000   \n",
      "4   they increase the violent tendencies among youth 0.0000000000   \n",
      "\n",
      "                                          pos_tagged  \n",
      "0  exposure_NN to_TO violent_VB video_NN games_NN...  \n",
      "1  video_NN game_NN violence_NN is_VBZ not_RB rel...  \n",
      "2  some_DT violent_JJ video_NNS games_NNS may_MD ...  \n",
      "3  exposure_NN to_TO violent_VB video_NN games_NN...  \n",
      "4  they_PRP increase_VBP the_DT violent_JJ tenden...  \n"
     ]
    }
   ],
   "source": [
    "n_gram_size = 1\n",
    "df = pd.read_csv(\"../classifier/data/combined_pos_tagged.csv\")\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "df = df[df['label'].notna()]\n",
    "\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "\n",
    "X = df['pos_tagged'].values.astype('U')\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "lr_classifier = Pipeline(\n",
    "                            [\n",
    "                                ('tvect', TfidfVectorizer(ngram_range=(1, n_gram_size))),\n",
    "                                ('ttrans', TfidfTransformer()),\n",
    "                                ('scaler', preprocessing.StandardScaler(with_mean=False)),\n",
    "                                ('cls', LogisticRegression(class_weight='balanced', dual=True, solver='liblinear', max_iter=10000))\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "dump(lr_classifier, r'../classifier/models/model_{}-gram.pkl'.format(n_gram_size))\n",
    "dump(lr_classifier, r'../classifier/models/model_{}-gram.joblib'.format(n_gram_size))\n",
    "y_pred = lr_classifier.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# TODO Need to find a way to oneHotEncode labels\n",
    "# print(\"ROC score: {}\".format(roc_auc_score(y_test, y_pred, multi_class='ovr')))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print()\n",
    "\n",
    "lr_classifier = load('../classifier/models/model_{}-gram.joblib'.format(n_gram_size))\n",
    "\n",
    "new_test_string = \"exposure to violent video games causes at least a temporary increase in aggression\"\n",
    "\n",
    "print(\"Raw string input: {}\".format(new_test_string))\n",
    "\n",
    "new_test_string = pre_process(new_test_string)\n",
    "new_test_string = tokenize_tag_combine(new_test_string)\n",
    "new_val = lr_classifier.predict_proba([new_test_string])\n",
    "\n",
    "print(\"Preprocessed string input: {}\".format(new_test_string))\n",
    "\n",
    "print()\n",
    "\n",
    "new_val_df = pd.DataFrame(new_val, columns=['claim', 'premise', 'both', 'neither'])\n",
    "\n",
    "print(\"Probability matrix:\")\n",
    "print(new_val_df.head())\n",
    "print()\n",
    "print(\"Probability sum: {}\".format(np.sum(new_val)))\n",
    "print()\n",
    "print(\"Cross validating\")\n",
    "\n",
    "accuracy = cross_val_score(lr_classifier, X, y, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"Cross validation array: {}\".format(accuracy))\n",
    "print(\"Cross validation average: {}\".format(np.mean(accuracy) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ea8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
