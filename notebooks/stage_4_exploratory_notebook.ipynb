{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1521a0",
   "metadata": {},
   "source": [
    "## Relatable Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0367952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import sklearn as sk\n",
    "import string\n",
    "from time import perf_counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7f7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(s):\n",
    "    # remove punctuation\n",
    "    s = \"\".join([char for char in s if char not in string.punctuation])\n",
    "\n",
    "    # filter stopwords\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords = stopwords.words('english')\n",
    "    s_tokenized = nltk.word_tokenize(s)\n",
    "    s_tokenized_stopwords_removed = [word for word in s_tokenized if word not in stopwords]\n",
    "    s_tokenized_stopwords_removed_joined = \" \".join(s_tokenized_stopwords_removed)\n",
    "    return s_tokenized_stopwords_removed_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a94017cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tag_combine(s):\n",
    "    s_tokenized = nltk.word_tokenize(s)\n",
    "    s_pos_tagged = nltk.pos_tag(s_tokenized)\n",
    "\n",
    "    new_s = ''\n",
    "    for word, pos in s_pos_tagged:\n",
    "        new_s = new_s + word + \"_\" + pos + \" \"\n",
    "\n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d6c2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    # read in data\n",
    "    df = pd.read_csv(r\"../classifier/data/combined.csv\")\n",
    "    df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    # get part of speech\n",
    "    test_string = \"This is a test string.\"\n",
    "    test_string = pre_process(test_string)\n",
    "    test_string = tokenize_tag_combine(test_string)\n",
    "\n",
    "    df['pos_tagged'] = df['text'].apply(tokenize_tag_combine)\n",
    "    \n",
    "\n",
    "    df.to_csv(r\"../classifier/data/combined_pos_tagged.csv\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5e449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_size = 1\n",
    "df = pd.read_csv(\"../classifier/data/combined_pos_tagged.csv\")\n",
    "df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "df = df[df['label'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8974dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pos_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exposure to violent video games causes at leas...</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>exposure_NN to_TO violent_VB video_NN games_NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video game violence is not related to serious ...</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>video_NN game_NN violence_NN is_VBZ not_RB rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>some violent video games may actually have a p...</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>some_DT violent_JJ video_NNS games_NNS may_MD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exposure to violent video games causes both sh...</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>exposure_NN to_TO violent_VB video_NN games_NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they increase the violent tendencies among youth</td>\n",
       "      <td>0.0000000000</td>\n",
       "      <td>they_PRP increase_VBP the_DT violent_JJ tenden...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label  \\\n",
       "0  exposure to violent video games causes at leas... 0.0000000000   \n",
       "1  video game violence is not related to serious ... 0.0000000000   \n",
       "2  some violent video games may actually have a p... 0.0000000000   \n",
       "3  exposure to violent video games causes both sh... 0.0000000000   \n",
       "4   they increase the violent tendencies among youth 0.0000000000   \n",
       "\n",
       "                                          pos_tagged  \n",
       "0  exposure_NN to_TO violent_VB video_NN games_NN...  \n",
       "1  video_NN game_NN violence_NN is_VBZ not_RB rel...  \n",
       "2  some_DT violent_JJ video_NNS games_NNS may_MD ...  \n",
       "3  exposure_NN to_TO violent_VB video_NN games_NN...  \n",
       "4  they_PRP increase_VBP the_DT violent_JJ tenden...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90dc0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['pos_tagged'].values.astype('U')\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = Pipeline(\n",
    "                            [\n",
    "                                ('tvect', TfidfVectorizer(ngram_range=(1, n_gram_size))),\n",
    "                                ('ttrans', TfidfTransformer()),\n",
    "                                ('scaler', preprocessing.StandardScaler(with_mean=False)),\n",
    "                                ('cls', LogisticRegression(class_weight='balanced', dual=True, solver='liblinear', max_iter=10000))\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "lr_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dccb797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(lr_classifier, r'../classifier/models/model_{}-gram.pkl'.format(n_gram_size))\n",
    "#dump(lr_classifier, r'../classifier/models/model_{}-gram.joblib'.format(n_gram_size))\n",
    "\n",
    "import gzip, pickle\n",
    "with gzip.open('../classifier/models/model_test.pkl', 'wb') as ofp:\n",
    "    pickle.dump(lr_classifier, ofp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_classifier.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# TODO Need to find a way to oneHotEncode labels\n",
    "# print(\"ROC score: {}\".format(roc_auc_score(y_test, y_pred, multi_class='ovr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "# lr_classifier = load('../classifier/models/model_{}-gram.joblib'.format(n_gram_size))\n",
    "# lr_classifier = pickle.load(open('../classifier/models/model_{}-gram.pkl'.format(n_gram_size), 'rb'))\n",
    "\n",
    "with gzip.open('../classifier/models/model_test.pkl', 'rb') as ifp:\n",
    "    print(pickle.load(ifp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_string = \"exposure to violent video games causes at least a temporary increase in aggression\"\n",
    "\n",
    "print(\"Raw string input: {}\".format(new_test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19b2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_string = pre_process(new_test_string)\n",
    "new_test_string = tokenize_tag_combine(new_test_string)\n",
    "new_val = lr_classifier.predict_proba([new_test_string])\n",
    "\n",
    "print(\"Preprocessed string input: {}\".format(new_test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc09ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_df = pd.DataFrame(new_val, columns=['claim', 'premise', 'both', 'neither'])\n",
    "\n",
    "print(\"Probability matrix:\")\n",
    "print(new_val_df.head())\n",
    "print()\n",
    "print(\"Probability sum: {}\".format(np.sum(new_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef372b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross validating\")\n",
    "\n",
    "accuracy = cross_val_score(lr_classifier, X, y, scoring='accuracy', cv=10)\n",
    "\n",
    "print(\"Cross validation array: {}\".format(accuracy))\n",
    "print(\"Cross validation average: {}\".format(np.mean(accuracy) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca1ba38",
   "metadata": {},
   "source": [
    "## Grabbing the training / testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703c371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
